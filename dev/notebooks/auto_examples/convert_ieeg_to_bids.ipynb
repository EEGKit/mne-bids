{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n.. currentmodule:: mne_bids\n\n# 08. Convert iEEG data to BIDS format\n\nIn this example, we use MNE-BIDS to create a BIDS-compatible directory of iEEG\ndata. Specifically, we will follow these steps:\n\n1. Download some iEEG data.\n\n2. Load the data, extract information, and save in a new BIDS directory.\n\n3. Check the result and compare it with the standard.\n\n4. Cite MNE-BIDS.\n\n5. Repeat the process for the ``fsaverage`` template coordinate frame.\n\nThe iEEG data will be written by :func:`write_raw_bids` with\nthe addition of extra metadata elements in the following files:\n\n- the sidecar file ``ieeg.json``\n- ``electrodes.tsv``\n- ``coordsystem.json``\n- ``events.tsv``\n- ``channels.tsv``\n\nCompared to EEG data, the main differences are within the\n``coordsystem.json`` and ``electrodes.tsv`` files.\nFor more information on these files,\nrefer to the `iEEG part of the BIDS specification`_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Adam Li <adam2392@gmail.com>\n#          Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n#          Alex Rockhill <aprockhill@mailbox.org>\n#\n# License: BSD-3-Clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport shutil\n\nfrom nilearn.plotting import plot_anat\n\nimport mne\nfrom mne_bids import (BIDSPath, write_raw_bids, write_anat,\n                      get_anat_landmarks, read_raw_bids,\n                      search_folder_for_text, print_dir_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Download the data\n\nFirst, we need some data to work with. We will use the\ndata downloaded via MNE-Python's ``datasets`` API:\n:func:`mne.datasets.misc.data_path`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "misc_path = mne.datasets.misc.data_path()\n\n# The electrode coords data are in the tsv file format\n# which is easily read in using numpy\nraw = mne.io.read_raw_fif(op.join(\n    misc_path, 'seeg', 'sample_seeg_ieeg.fif'))\nraw.info['line_freq'] = 60  # specify power line frequency as required by BIDS\nsubjects_dir = op.join(misc_path, 'seeg')  # Freesurfer recon-all directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the locations of the channels in this dataset were found\nin `Locating Intracranial Electrode Contacts\n<https://mne.tools/dev/auto_tutorials/clinical/10_ieeg_localize.html>`_,\nthe T1 was aligned to ACPC. So, this montage is in an\n`ACPC-aligned coordinate system\n<https://surfer.nmr.mgh.harvard.edu/fswiki/CoordinateSystems>`_.\nWe can either save the channel positions in the subject's anatomical\nspace (from their T1 image) or we can transform to a template space\nsuch as ``fsaverage``. To save them in the individual space, it is\nrequired that the T1 have been aligned to ACPC and then the channel positions\nbe in terms of that coordinate system. Automated alignment to ACPC has not\nbeen implemented in MNE yet, so if the channel positions are not in\nan ACPC-aligned coordinate system, using a template (like ``fsaverage``)\nis the best option.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# estimate the transformation from \"head\" to \"mri\" space\ntrans = mne.coreg.estimate_head_mri_t('sample_seeg', subjects_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's convert the montage to \"mri\"\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\nmontage.apply_trans(trans)  # head->mri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BIDS vs MNE-Python Coordinate Systems\n\nBIDS has many acceptable coordinate systems for iEEG, which can be viewed in\n`appendix VIII`_ of the BIDS specification.\nHowever, MNE-BIDS depends on MNE-Python and MNE-Python does not support all\nthese coordinate systems (yet).\n\nMNE-Python has a few tutorials on this topic:\n\n- `background on FreeSurfer`_\n- `MNE-Python coordinate frames`_\n\nCurrently, MNE-Python supports the ``mni_tal`` and ``mri`` coordinate frames,\ncorresponding to the ``fsaverage`` and ``ACPC`` (for an ACPC-aligned T1) BIDS\ncoordinate systems respectively. All other coordinate coordinate frames in\nMNE-Python if written with :func:`mne_bids.write_raw_bids` are written with\ncoordinate system ``'Other'``. Note, then we suggest using\n:func:`mne_bids.update_sidecar_json` to update the sidecar\n``*_coordsystem.json`` file to add additional information.\n\n## Step 2: Formatting as BIDS\n\nNow, let us format the `Raw` object into BIDS.\n\nWith this step, we have everything to start a new BIDS directory using\nour data. To do that, we can use :func:`write_raw_bids`\nGenerally, :func:`write_raw_bids` tries to extract as much\nmeta data as possible from the raw data and then formats it in a BIDS\ncompatible way. :func:`write_raw_bids` takes a bunch of inputs, most of\nwhich are however optional. The required inputs are:\n\n- :code:`raw`\n- :code:`bids_basename`\n- :code:`bids_root`\n\n... as you can see in the docstring:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(write_raw_bids.__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us initialize some of the necessary data for the subject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# There is a subject, and specific task for the dataset.\nsubject_id = '1'\ntask = 'motor'\n\n# get MNE-Python directory w/ example data\nmne_data_dir = mne.get_config('MNE_DATASETS_MISC_PATH')\n\n# There is the root directory for where we will write our data.\nbids_root = op.join(mne_data_dir, 'ieeg_bids')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To ensure the output path doesn't contain any leftover files from previous\ntests and example runs, we simply delete it.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Do not delete directories that may contain important data!</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if op.exists(bids_root):\n    shutil.rmtree(bids_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we just need make a :class:`mne_bids.BIDSPath` to save the data.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>By passing ``acpc_aligned=True``, we are affirming that\n             the T1 in this dataset is aligned to ACPC. This is very\n             difficult to check with a computer which is why this\n             step is required.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now convert our data to be in a new BIDS dataset.\nbids_path = BIDSPath(subject=subject_id, task=task, root=bids_root)\n\n# plot T1 to show that it is ACPC-aligned\n# note that the origin is centered on the anterior commissure (AC)\n# with the y-axis passing through the posterior commissure (PC)\nT1_fname = op.join(subjects_dir, 'sample_seeg', 'mri', 'T1.mgz')\nfig = plot_anat(T1_fname, cut_coords=(0, 0, 0))\nfig.axes['x'].ax.annotate('AC', (2., -2.), (30., -40.), color='w',\n                          arrowprops=dict(facecolor='w', alpha=0.5))\nfig.axes['x'].ax.annotate('PC', (-31., -2.), (-80., -40.), color='w',\n                          arrowprops=dict(facecolor='w', alpha=0.5))\n\n# write ACPC-aligned T1\nlandmarks = get_anat_landmarks(T1_fname, raw.info, trans,\n                               'sample_seeg', subjects_dir)\nT1_bids_path = write_anat(T1_fname, bids_path, deface=True,\n                          landmarks=landmarks)\n\n# write `raw` to BIDS and anonymize it (converts to BrainVision format)\n#\n# we need to pass the `montage` argument for coordinate frames other than\n# \"head\" which is what MNE uses internally in the `raw` object\n#\n# `acpc_aligned=True` affirms that our MRI is aligned to ACPC\n# if this is not true, convert to `fsaverage` (see below)!\nwrite_raw_bids(raw, bids_path, anonymize=dict(daysback=40000),\n               montage=montage, acpc_aligned=True, overwrite=True)\n\n# check our output\nprint_dir_tree(bids_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MNE-BIDS has created a suitable directory structure for us, and among other\nmeta data files, it started an ``events.tsv``` and ``channels.tsv`` file,\nand created an initial ``dataset_description.json`` file on top!\n\nNow it's time to manually check the BIDS directory and the meta files to add\nall the information that MNE-BIDS could not infer. For instance, you must\ndescribe ``iEEGReference`` and ``iEEGGround`` yourself.\nIt's easy to find these by searching for ``\"n/a\"`` in the sidecar files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search_folder_for_text('n/a', bids_root)\n\n# Remember that there is a convenient JavaScript tool to validate all your BIDS\n# directories called the \"BIDS-validator\", available as a web version and a\n# command line tool:\n#\n# Web version: https://bids-standard.github.io/bids-validator/\n#\n# Command line tool: https://www.npmjs.com/package/bids-validator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load channels from BIDS-formatted dataset and compare\n\nNow we have written our BIDS directory. We can use\n:func:`read_raw_bids` to read in the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# read in the BIDS dataset to plot the coordinates\nraw = read_raw_bids(bids_path=bids_path)\n\n# compare with standard\nprint('Recovered coordinate: {recovered}\\n'\n      'Saved coordinate:     {saved}'.format(\n          recovered=raw.info['chs'][0]['loc'][:3],\n          saved=montage.dig[0]['r']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have to go back to \"head\" coordinates with the head->mri transform.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you were downloading this from ``OpenNeuro``, you would\n          have to run the Freesurfer ``recon-all`` to get the transforms.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\n# this uses Freesurfer recon-all subject directory\nmontage.add_estimated_fiducials('sample_seeg', subjects_dir=subjects_dir)\n# now the montage is properly in \"head\" and ready for analysis in MNE\nraw.set_montage(montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Cite mne-bids\nWe can see that the appropriate citations are already written in the README.\nIf you are preparing a manuscript, please make sure to also cite MNE-BIDS\nthere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "readme = op.join(bids_root, 'README')\nwith open(readme, 'r', encoding='utf-8-sig') as fid:\n    text = fid.read()\nprint(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Store coordinates in a template space\nAlternatively, if your T1 is not aligned to ACPC-space or you prefer to\nstore the coordinates in a template space (e.g. ``fsaverage``) for another\nreason, you can also do that.\n\nHere we'll use the MNI Talairach transform to get to ``fsaverage`` space\nfrom \"mri\" aka surface RAS space.\n``fsaverage`` is very useful for group analysis as shown in\n`tut-working-with-seeg`. Note, this is only a linear transform and so\none loses quite a bit of accuracy relative to the needs of intracranial\nresearchers so it is quite suboptimal. A better option is to use a\nsymmetric diffeomorphic transform to create a one-to-one mapping of brain\nvoxels from the individual's brain to the template as shown in\n`tut-ieeg-localize`. Even so, it's better to provide the coordinates\nin the individual's brain space, as was done above, so that the researcher\nwho uses the coordinates has the ability to tranform them to a template\nof their choice.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ensure the output path doesn't contain any leftover files from previous\n# tests and example runs\nif op.exists(bids_root):\n    shutil.rmtree(bids_root)\n\n# load our raw data again\nraw = mne.io.read_raw_fif(op.join(\n    misc_path, 'seeg', 'sample_seeg_ieeg.fif'))\nraw.info['line_freq'] = 60  # specify power line frequency as required by BIDS\n\n# get Talairach transform\nmri_mni_t = mne.read_talxfm('sample_seeg', subjects_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's convert the montage to MNI Talairach (\"mni_tal\").\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\nmontage.apply_trans(trans)  # head->mri\nmontage.apply_trans(mri_mni_t)\n\n# write to BIDS, this time with a template coordinate system\nwrite_raw_bids(raw, bids_path, anonymize=dict(daysback=40000),\n               montage=montage, overwrite=True)\n\n# read in the BIDS dataset\nraw = read_raw_bids(bids_path=bids_path)\n\n# check that we can recover the coordinates\nprint('Recovered coordinate: {recovered}\\n'\n      'Saved coordinate:     {saved}'.format(\n          recovered=raw.info['chs'][0]['loc'][:3],\n          saved=montage.dig[0]['r']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we should go back to \"head\" coordinates. We do this with ``fsaverage``\nfiducials which are in MNI space. In this case, you would not need to run\nthe Freesurfer ``recon-all`` for the subject, you would just need a\n``subjects_dir`` with ``fsaverage`` in it, which is accessible using\n:func:`mne.datasets.fetch_fsaverage`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\n# add fiducials for \"mni_tal\" (which is the coordinate frame fsaverage is in)\n# so that it can properly be set to \"head\"\nmontage.add_mni_fiducials(subjects_dir=subjects_dir)\n\n# Many other templates are included in the Freesurfer installation,\n# so, for those, the fiducials can be estimated with\n# ``montage.add_estimated_fiducials(template, os.environ['FREESURFER_HOME'])``\n# where ``template`` maybe be ``cvs_avg35_inMNI152`` for instance\nraw.set_montage(montage)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}