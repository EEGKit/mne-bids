{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n.. currentmodule:: mne_bids\n\n# 08. Convert iEEG data to BIDS format\n\nIn this example, we use MNE-BIDS to create a BIDS-compatible directory of iEEG\ndata. Specifically, we will follow these steps:\n\n1. Download some iEEG data.\n\n2. Load the data, extract information, and save in a new BIDS directory.\n\n3. Check the result and compare it with the standard.\n\n4. Cite MNE-BIDS.\n\n5. Repeat the process for the ``fsaverage`` template coordinate frame.\n\n6. Repeat the process for one of the other standard template coordinate frames\n   allowed by BIDS.\n\nThe iEEG data will be written by :func:`write_raw_bids` with\nthe addition of extra metadata elements in the following files:\n\n- the sidecar file ``ieeg.json``\n- ``electrodes.tsv``\n- ``coordsystem.json``\n- ``events.tsv``\n- ``channels.tsv``\n\nCompared to EEG data, the main differences are within the\n``coordsystem.json`` and ``electrodes.tsv`` files.\nFor more information on these files,\nrefer to the `iEEG part of the BIDS specification`_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Adam Li <adam2392@gmail.com>\n#          Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n#          Alex Rockhill <aprockhill@mailbox.org>\n#\n# License: BSD-3-Clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport numpy as np\nimport shutil\n\nfrom nilearn.plotting import plot_anat\n\nimport mne\nfrom mne_bids import (BIDSPath, write_raw_bids, write_anat,\n                      get_anat_landmarks, read_raw_bids,\n                      search_folder_for_text, print_dir_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Download the data\n\nFirst, we need some data to work with. We will use the\ndata downloaded via MNE-Python's ``datasets`` API:\n:func:`mne.datasets.misc.data_path`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "misc_path = mne.datasets.misc.data_path()\n\n# The electrode coords data are in the tsv file format\n# which is easily read in using numpy\nraw = mne.io.read_raw_fif(op.join(\n    misc_path, 'seeg', 'sample_seeg_ieeg.fif'))\nraw.info['line_freq'] = 60  # specify power line frequency as required by BIDS\nsubjects_dir = op.join(misc_path, 'seeg')  # Freesurfer recon-all directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the locations of the channels in this dataset were found\nin `Locating Intracranial Electrode Contacts\n<https://mne.tools/dev/auto_tutorials/clinical/10_ieeg_localize.html>`_,\nthe T1 was aligned to ACPC. So, this montage is in an\n`ACPC-aligned coordinate system\n<https://surfer.nmr.mgh.harvard.edu/fswiki/CoordinateSystems>`_.\nWe can either save the channel positions in the subject's anatomical\nspace (from their T1 image) or we can transform to a template space\nsuch as ``fsaverage``. To save them in the individual space, it is\nrequired that the T1 have been aligned to ACPC and then the channel positions\nbe in terms of that coordinate system. Automated alignment to ACPC has not\nbeen implemented in MNE yet, so if the channel positions are not in\nan ACPC-aligned coordinate system, using a template (like ``fsaverage``)\nis the best option.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# estimate the transformation from \"head\" to \"mri\" space\ntrans = mne.coreg.estimate_head_mri_t('sample_seeg', subjects_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's convert the montage to \"mri\"\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\nmontage.apply_trans(trans)  # head->mri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BIDS vs MNE-Python Coordinate Systems\n\nBIDS has many acceptable coordinate systems for iEEG, which can be viewed in\n`appendix VIII`_ of the BIDS specification.\nHowever, MNE-BIDS depends on MNE-Python and MNE-Python does not support all\nthese coordinate systems (yet).\n\nMNE-Python has a few tutorials on this topic:\n\n- `background on FreeSurfer`_\n- `MNE-Python coordinate frames`_\n\nCurrently, MNE-Python supports the ``mni_tal`` and ``mri`` coordinate frames,\ncorresponding to the ``fsaverage`` and ``ACPC`` (for an ACPC-aligned T1) BIDS\ncoordinate systems respectively. All other coordinate coordinate frames in\nMNE-Python if written with :func:`mne_bids.write_raw_bids` are written with\ncoordinate system ``'Other'``. Note, then we suggest using\n:func:`mne_bids.update_sidecar_json` to update the sidecar\n``*_coordsystem.json`` file to add additional information.\n\n## Step 2: Formatting as BIDS\n\nNow, let us format the `Raw` object into BIDS.\n\nWith this step, we have everything to start a new BIDS directory using\nour data. To do that, we can use :func:`write_raw_bids`\nGenerally, :func:`write_raw_bids` tries to extract as much\nmeta data as possible from the raw data and then formats it in a BIDS\ncompatible way. :func:`write_raw_bids` takes a bunch of inputs, most of\nwhich are however optional. The required inputs are:\n\n- :code:`raw`\n- :code:`bids_basename`\n- :code:`bids_root`\n\n... as you can see in the docstring:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(write_raw_bids.__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us initialize some of the necessary data for the subject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# There is a subject, and specific task for the dataset.\nsubject_id = '1'\ntask = 'motor'\n\n# get MNE-Python directory w/ example data\nmne_data_dir = mne.get_config('MNE_DATASETS_MISC_PATH')\n\n# There is the root directory for where we will write our data.\nbids_root = op.join(mne_data_dir, 'ieeg_bids')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To ensure the output path doesn't contain any leftover files from previous\ntests and example runs, we simply delete it.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Do not delete directories that may contain important data!</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if op.exists(bids_root):\n    shutil.rmtree(bids_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we just need make a :class:`mne_bids.BIDSPath` to save the data.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>By passing ``acpc_aligned=True``, we are affirming that\n             the T1 in this dataset is aligned to ACPC. This is very\n             difficult to check with a computer which is why this\n             step is required.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now convert our data to be in a new BIDS dataset.\nbids_path = BIDSPath(subject=subject_id, task=task, root=bids_root)\n\n# plot T1 to show that it is ACPC-aligned\n# note that the origin is centered on the anterior commissure (AC)\n# with the y-axis passing through the posterior commissure (PC)\nT1_fname = op.join(subjects_dir, 'sample_seeg', 'mri', 'T1.mgz')\nfig = plot_anat(T1_fname, cut_coords=(0, 0, 0))\nfig.axes['x'].ax.annotate('AC', (2., -2.), (30., -40.), color='w',\n                          arrowprops=dict(facecolor='w', alpha=0.5))\nfig.axes['x'].ax.annotate('PC', (-31., -2.), (-80., -40.), color='w',\n                          arrowprops=dict(facecolor='w', alpha=0.5))\n\n# write ACPC-aligned T1\nlandmarks = get_anat_landmarks(T1_fname, raw.info, trans,\n                               'sample_seeg', subjects_dir)\nT1_bids_path = write_anat(T1_fname, bids_path, deface=True,\n                          landmarks=landmarks)\n\n# write `raw` to BIDS and anonymize it (converts to BrainVision format)\n#\n# we need to pass the `montage` argument for coordinate frames other than\n# \"head\" which is what MNE uses internally in the `raw` object\n#\n# `acpc_aligned=True` affirms that our MRI is aligned to ACPC\n# if this is not true, convert to `fsaverage` (see below)!\nwrite_raw_bids(raw, bids_path, anonymize=dict(daysback=40000),\n               montage=montage, acpc_aligned=True, overwrite=True)\n\n# check our output\nprint_dir_tree(bids_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MNE-BIDS has created a suitable directory structure for us, and among other\nmeta data files, it started an ``events.tsv``` and ``channels.tsv`` file,\nand created an initial ``dataset_description.json`` file on top!\n\nNow it's time to manually check the BIDS directory and the meta files to add\nall the information that MNE-BIDS could not infer. For instance, you must\ndescribe ``iEEGReference`` and ``iEEGGround`` yourself.\nIt's easy to find these by searching for ``\"n/a\"`` in the sidecar files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "search_folder_for_text('n/a', bids_root)\n\n# Remember that there is a convenient JavaScript tool to validate all your BIDS\n# directories called the \"BIDS-validator\", available as a web version and a\n# command line tool:\n#\n# Web version: https://bids-standard.github.io/bids-validator/\n#\n# Command line tool: https://www.npmjs.com/package/bids-validator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load channels from BIDS-formatted dataset and compare\n\nNow we have written our BIDS directory. We can use\n:func:`read_raw_bids` to read in the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# read in the BIDS dataset to plot the coordinates\nraw = read_raw_bids(bids_path=bids_path)\n\n# compare with standard\nprint('Recovered coordinate: {recovered}\\n'\n      'Saved coordinate:     {saved}'.format(\n          recovered=raw.info['chs'][0]['loc'][:3],\n          saved=montage.dig[0]['r']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have to go back to \"head\" coordinates with the head->mri transform.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you were downloading this from ``OpenNeuro``, you would\n          have to run the Freesurfer ``recon-all`` to get the transforms.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\n# this uses Freesurfer recon-all subject directory\nmontage.add_estimated_fiducials('sample_seeg', subjects_dir=subjects_dir)\n# now the montage is properly in \"head\" and ready for analysis in MNE\nraw.set_montage(montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Cite mne-bids\nWe can see that the appropriate citations are already written in the README.\nIf you are preparing a manuscript, please make sure to also cite MNE-BIDS\nthere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "readme = op.join(bids_root, 'README')\nwith open(readme, 'r', encoding='utf-8-sig') as fid:\n    text = fid.read()\nprint(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Store coordinates in a template space\nAlternatively, if your T1 is not aligned to ACPC-space or you prefer to\nstore the coordinates in a template space (e.g. ``fsaverage``) for another\nreason, you can also do that.\n\nHere we'll use the MNI Talairach transform to get to ``fsaverage`` space\nfrom \"mri\" aka surface RAS space.\n``fsaverage`` is very useful for group analysis as shown in\n`tut-working-with-seeg`. Note, this is only a linear transform and so\none loses quite a bit of accuracy relative to the needs of intracranial\nresearchers so it is quite suboptimal. A better option is to use a\nsymmetric diffeomorphic transform to create a one-to-one mapping of brain\nvoxels from the individual's brain to the template as shown in\n`tut-ieeg-localize`. Even so, it's better to provide the coordinates\nin the individual's brain space, as was done above, so that the researcher\nwho uses the coordinates has the ability to tranform them to a template\nof their choice.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ensure the output path doesn't contain any leftover files from previous\n# tests and example runs\nif op.exists(bids_root):\n    shutil.rmtree(bids_root)\n\n# load our raw data again\nraw = mne.io.read_raw_fif(op.join(\n    misc_path, 'seeg', 'sample_seeg_ieeg.fif'))\nraw.info['line_freq'] = 60  # specify power line frequency as required by BIDS\n\n# get Talairach transform\nmri_mni_t = mne.read_talxfm('sample_seeg', subjects_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's convert the montage to MNI Talairach (\"mni_tal\").\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\nmontage.apply_trans(trans)  # head->mri\nmontage.apply_trans(mri_mni_t)\n\n# write to BIDS, this time with a template coordinate system\nwrite_raw_bids(raw, bids_path, anonymize=dict(daysback=40000),\n               montage=montage, overwrite=True)\n\n# read in the BIDS dataset\nraw = read_raw_bids(bids_path=bids_path)\n\n# check that we can recover the coordinates\nprint('Recovered coordinate: {recovered}\\n'\n      'Saved coordinate:     {saved}'.format(\n          recovered=raw.info['chs'][0]['loc'][:3],\n          saved=montage.dig[0]['r']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we should go back to \"head\" coordinates. We do this with ``fsaverage``\nfiducials which are in MNI space. In this case, you would not need to run\nthe Freesurfer ``recon-all`` for the subject, you would just need a\n``subjects_dir`` with ``fsaverage`` in it, which is accessible using\n:func:`mne.datasets.fetch_fsaverage`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = raw.get_montage()\n# add fiducials for \"mni_tal\" (which is the coordinate frame fsaverage is in)\n# so that it can properly be set to \"head\"\nmontage.add_mni_fiducials(subjects_dir=subjects_dir)\n\n# Many other templates are included in the Freesurfer installation,\n# so, for those, the fiducials can be estimated with\n# ``montage.add_estimated_fiducials(template, os.environ['FREESURFER_HOME'])``\n# where ``template`` maybe be ``cvs_avg35_inMNI152`` for instance\nraw.set_montage(montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Store coordinates in another template space accepted by BIDS\nAs of this writing, BIDS accepts channel coordinates in reference to the\nthe following template spaces: ``ICBM452AirSpace``, ``ICBM452Warp5Space``,\n``IXI549Space``, ``fsaverage``, ``fsaverageSym``, ``fsLR``, ``MNIColin27``,\n``MNI152Lin``, ``MNI152NLin2009[a-c][Sym|Asym]``, ``MNI152NLin6Sym``,\n``MNI152NLin6ASym``, ``MNI305``, ``NIHPD``, ``OASIS30AntsOASISAnts``,\n``OASIS30Atropos``, ``Talairach`` and ``UNCInfant``. As discussed above,\nit is recommended to share the coordinates in the individual subject's\nanatomical reference frame so that researchers who use the data can\ntransform the coordinates to any of these templates that they choose. If\nBIDS-formatted data is shared in one of these template coordinate frames,\nthe data can still be analyzed in MNE-Python. However, MNE-Python only\nrecognizes a few coordinate frames (so that coordinate frames that are\nnot regularly used by the MNE community don't misleadingly appear to be\nbeing fully maintained when they are not) so you'll need a bit more\nknow-how, which we will go over below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ensure the output path doesn't contain any leftover files from previous\n# tests and example runs\nif op.exists(bids_root):\n    shutil.rmtree(bids_root)\n\n\n# first we'll write our data as if it were MNI152NLin2009bAsym coordinates\n# (you would need to transform your coordinates to this template first)\nbids_path.update(datatype='ieeg', space='MNI152NLin2009bAsym')\n\n# load our raw data again\nraw = mne.io.read_raw_fif(op.join(\n    misc_path, 'seeg', 'sample_seeg_ieeg.fif'))\nraw.info['line_freq'] = 60  # specify power line frequency as required by BIDS\n\n# get the montage as stored in raw\n# MNE stores coordinates in raw objects in \"head\" coordinates for consistency\nmontage = raw.get_montage()\n\n# define a transform to MNI152NLin2009bAsym (fake it)\n# MNE-Python doesn't recognize MNI152NLin2009bAsym, so we have to use\n# the unknown coordinate frame\nhead_template_t = np.array([[1.0, 0.1, 0.2, 10.1],\n                            [-0.1, 1.0, 0.1, -20.3],\n                            [0.2, -0.1, 1.0, -30.7],\n                            [0.0, 0.0, 0.0, 1.0]])\nhead_template_trans = mne.transforms.Transform(\n    fro='head', to='unknown', trans=head_template_t)\nmontage.apply_trans(head_template_trans)\n\n# write to BIDS, with the montage in fsaverage coordinates\nwrite_raw_bids(raw, bids_path, anonymize=dict(daysback=40000),\n               montage=montage, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's see how we would work with the data in MNE. As shown below, the\nmontage has the same coordinates as when it was written, but the coordinate\nframe is unknown.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# read back in the raw data\nraw = read_raw_bids(bids_path=bids_path)\n\n# get the montage\nmontage2 = raw.get_montage()\nprint('Montage set to: ' + montage2.get_positions()['coord_frame'])\n\n# check that we can recover the coordinates\nprint('Recovered coordinate: {recovered}\\n'\n      'Saved coordinate:     {saved}'.format(\n          recovered=montage2.dig[0]['r'],\n          saved=montage.dig[0]['r']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To work with this data in the template coordinate frame, all the same steps\ncan be followed in `tut-working-with-seeg` and\n`tut-working-with-ecog` after the montage is transformed to surface\nRAS coordinates for the template MRI (if it isn't there already).\n\nFirst we'll need the ``subjects_dir`` where the recon-all for the template\nbrain is stored.\n\n.. code-block:: python\n\n   subjects_dir = op.join(misc_path, 'subjects')  # for example\n   # add some plotting keyword arguments\n   brain_kwargs = dict(cortex='low_contrast', alpha=0.2, background='white')\n\nIf the montage is already in surface RAS for the template MRI, we can use:\n\n.. code-block:: python\n\n     # identity transform since 'unknown' is already 'mri' == surface RAS\n     # for the template brain MRI\n     trans = mne.transforms.Transform(\n         fro='unknown',\n         to='mri',\n         trans=np.eye(4)\n     )\n     brain = mne.viz.Brain('sample_seeg', subjects_dir=subjects_dir,\n         **brain_kwargs)\n     brain.add_sensors(raw.info, trans=trans)\n\nIf the montage was in voxel coordinates, we'll first have to transform\nto surface RAS:\n\n.. code-block:: python\n\n     import nibabel as nib\n     template_T1 = nib.load(op.join(subjects_dir, 'MNI152NLin2009bAsym',\n                                    'mri', 'T1.mgz'))\n     trans = mne.transforms.Transform(  # use vox to surface RAS transform\n         fro='unknown',\n         to='mri',\n         trans=template_T1.header.get_vox2ras_tkr()\n     )\n     brain = mne.viz.Brain(\n         'sample_seeg', subjects_dir=subjects_dir, **brain_kwargs)\n     brain.add_sensors(raw.info, trans=trans)\n\n\nFinally, if the montage was in scanner RAS coordinates, we'll have to\ntransform it back to voxels first before going to surface RAS:\n\n.. code-block:: python\n\n     import nibabel as nib\n     template_T1 = nib.load(op.join(subjects_dir, 'MNI152NLin2009bAsym',\n                                    'mri', 'T1.mgz'))\n     ras_vox_t = template_T1.header.get_ras2vox()\n     vox_mri_t = template_T1.header.get_vox2ras_tkr()\n     ras_mri_t = np.dot(ras_vox_t, vox_mri_t)  # ras->vox with vox->mri\n     trans = mne.transforms.Transform(\n         fro='unknown',\n         to='mri',\n         trans=ras_mri_t\n     )\n     brain = mne.viz.Brain(\n         'sample_seeg', subjects_dir=subjects_dir, **brain_kwargs)\n     brain.add_sensors(raw.info, trans=trans)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}